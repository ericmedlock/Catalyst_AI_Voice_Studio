{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalyst AI Voice Studio Demo\n",
    "\n",
    "This notebook demonstrates the basic workflows of the Catalyst AI Voice Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import voice studio modules\n",
    "from catalyst_ai_voice_studio.tts_service import XTTSLoader, OpenVoiceLoader\n",
    "from catalyst_ai_voice_studio.text_normalizer import TextNormalizer\n",
    "from catalyst_ai_voice_studio.prosody_planner import ProsodyPlanner\n",
    "from catalyst_ai_voice_studio.utils.audio_tools import normalize_audio\n",
    "\n",
    "# For audio playback and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Text-to-Speech Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TTS model\n",
    "tts = XTTSLoader()\n",
    "tts.load_model()\n",
    "\n",
    "print(f\"Model loaded: {tts.is_model_loaded()}\")\n",
    "print(f\"Sample rate: {tts.sample_rate} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple synthesis\n",
    "text = \"Hello, world! This is a demonstration of the Catalyst AI Voice Studio.\"\n",
    "\n",
    "audio = tts.synthesize(text, voice_id=\"default\")\n",
    "\n",
    "print(f\"Generated audio: {len(audio)} samples\")\n",
    "print(f\"Duration: {len(audio) / tts.sample_rate:.2f} seconds\")\n",
    "\n",
    "# Play audio\n",
    "display(Audio(audio, rate=tts.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text normalizer\n",
    "normalizer = TextNormalizer()\n",
    "\n",
    "# Test text with various elements that need normalization\n",
    "raw_text = \"\"\"\n",
    "Dr. Smith said: \"The meeting is at 3:30 PM on Dec. 15th, 2023.\n",
    "We'll discuss the $1,000,000 budget & Q4 results.\"\n",
    "Contact him @ john.smith@company.com or call (555) 123-4567.\n",
    "\"\"\"\n",
    "\n",
    "normalized_text = normalizer.normalize(raw_text)\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(raw_text)\n",
    "print(\"\\nNormalized text:\")\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prosody Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize prosody planner\n",
    "prosody_planner = ProsodyPlanner()\n",
    "\n",
    "# Test text with various prosodic elements\n",
    "test_text = \"Hello, my name is John. I'm *very* excited to meet you! This is IMPORTANT information.\"\n",
    "\n",
    "# Plan prosody\n",
    "markers = prosody_planner.plan_prosody(test_text)\n",
    "\n",
    "print(f\"Found {len(markers)} prosody markers:\")\n",
    "for marker in markers:\n",
    "    print(f\"  Position {marker.position}: {marker.marker_type} (strength: {marker.strength:.2f})\")\n",
    "\n",
    "# Apply prosody\n",
    "prosody_text = prosody_planner.apply_prosody(test_text, markers)\n",
    "print(\"\\nText with prosody markup:\")\n",
    "print(prosody_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_with_pipeline(text, voice_id=\"default\", model=\"xtts\"):\n",
    "    \"\"\"Complete TTS pipeline with normalization and prosody.\"\"\"\n",
    "    \n",
    "    # Step 1: Load model\n",
    "    if model == \"xtts\":\n",
    "        tts_model = XTTSLoader()\n",
    "    elif model == \"openvoice\":\n",
    "        tts_model = OpenVoiceLoader()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model}\")\n",
    "    \n",
    "    tts_model.load_model()\n",
    "    \n",
    "    # Step 2: Normalize text\n",
    "    normalizer = TextNormalizer()\n",
    "    normalized_text = normalizer.normalize(text)\n",
    "    \n",
    "    # Step 3: Plan prosody\n",
    "    prosody_planner = ProsodyPlanner()\n",
    "    markers = prosody_planner.plan_prosody(normalized_text)\n",
    "    prosody_text = prosody_planner.apply_prosody(normalized_text, markers)\n",
    "    \n",
    "    # Step 4: Synthesize\n",
    "    audio = tts_model.synthesize(prosody_text, voice_id=voice_id)\n",
    "    \n",
    "    # Step 5: Post-process audio\n",
    "    audio = normalize_audio(audio)\n",
    "    \n",
    "    return audio, tts_model.sample_rate, {\n",
    "        \"original_text\": text,\n",
    "        \"normalized_text\": normalized_text,\n",
    "        \"prosody_text\": prosody_text,\n",
    "        \"prosody_markers\": len(markers),\n",
    "        \"duration\": len(audio) / tts_model.sample_rate\n",
    "    }\n",
    "\n",
    "# Test the complete pipeline\n",
    "test_text = \"\"\"\n",
    "Welcome to Catalyst AI Voice Studio! This is a *professional-grade* \n",
    "voice synthesis platform. It supports multiple TTS backends, \n",
    "including XTTS-v2 & OpenVoice. The system can handle complex text \n",
    "normalization: numbers like 123, dates like Dec. 15th, 2023, \n",
    "and abbreviations like Dr. Smith. Isn't that amazing?\n",
    "\"\"\"\n",
    "\n",
    "audio, sample_rate, info = synthesize_with_pipeline(test_text)\n",
    "\n",
    "print(\"Pipeline Results:\")\n",
    "for key, value in info.items():\n",
    "    if isinstance(value, str) and len(value) > 100:\n",
    "        print(f\"{key}: {value[:100]}...\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Play the result\n",
    "display(Audio(audio, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Voice Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different voices\n",
    "comparison_text = \"This is a voice comparison test. How do I sound?\"\n",
    "\n",
    "# Get available voices\n",
    "voices = tts.get_voices()\n",
    "print(\"Available voices:\")\n",
    "for voice_id, info in voices.items():\n",
    "    print(f\"  {voice_id}: {info['name']}\")\n",
    "\n",
    "# Generate audio for each voice\n",
    "voice_samples = {}\n",
    "for voice_id in list(voices.keys())[:3]:  # Limit to first 3 voices\n",
    "    print(f\"\\nGenerating sample for {voice_id}...\")\n",
    "    audio = tts.synthesize(comparison_text, voice_id=voice_id)\n",
    "    voice_samples[voice_id] = audio\n",
    "    \n",
    "    print(f\"Voice: {voices[voice_id]['name']}\")\n",
    "    display(Audio(audio, rate=tts.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Audio Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize generated audio\n",
    "sample_audio = tts.synthesize(\"This is a sample for visualization.\")\n",
    "\n",
    "# Time axis\n",
    "time_axis = np.linspace(0, len(sample_audio) / tts.sample_rate, len(sample_audio))\n",
    "\n",
    "# Create plots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Waveform\n",
    "ax1.plot(time_axis, sample_audio)\n",
    "ax1.set_title('Waveform')\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Spectrogram\n",
    "import librosa\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(sample_audio)), ref=np.max)\n",
    "img = librosa.display.specshow(D, y_axis='hz', x_axis='time', sr=tts.sample_rate, ax=ax2)\n",
    "ax2.set_title('Spectrogram')\n",
    "fig.colorbar(img, ax=ax2, format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Play the audio\n",
    "display(Audio(sample_audio, rate=tts.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate streaming synthesis\n",
    "streaming_text = \"\"\"\n",
    "This is a demonstration of streaming synthesis. \n",
    "The audio is generated in chunks, which allows for \n",
    "real-time playback and lower latency applications. \n",
    "This is particularly useful for interactive applications \n",
    "and live voice assistants.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Streaming synthesis...\")\n",
    "chunks = []\n",
    "chunk_count = 0\n",
    "\n",
    "for chunk in tts.stream(streaming_text, chunk_size=1024):\n",
    "    chunks.append(chunk)\n",
    "    chunk_count += 1\n",
    "    print(f\"Received chunk {chunk_count}: {len(chunk)} samples\")\n",
    "\n",
    "# Concatenate chunks\n",
    "full_audio = np.concatenate(chunks)\n",
    "\n",
    "print(f\"\\nStreaming complete: {chunk_count} chunks, {len(full_audio)} total samples\")\n",
    "print(f\"Duration: {len(full_audio) / tts.sample_rate:.2f} seconds\")\n",
    "\n",
    "# Play the result\n",
    "display(Audio(full_audio, rate=tts.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare XTTS and OpenVoice models\n",
    "comparison_text = \"This is a model comparison between XTTS and OpenVoice.\"\n",
    "\n",
    "models = {\n",
    "    \"XTTS\": XTTSLoader(),\n",
    "    \"OpenVoice\": OpenVoiceLoader()\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTesting {model_name}...\")\n",
    "    model.load_model()\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    audio = model.synthesize(comparison_text)\n",
    "    synthesis_time = time.time() - start_time\n",
    "    \n",
    "    model_results[model_name] = {\n",
    "        \"audio\": audio,\n",
    "        \"sample_rate\": model.sample_rate,\n",
    "        \"synthesis_time\": synthesis_time,\n",
    "        \"duration\": len(audio) / model.sample_rate,\n",
    "        \"rtf\": synthesis_time / (len(audio) / model.sample_rate)\n",
    "    }\n",
    "    \n",
    "    print(f\"Sample rate: {model.sample_rate} Hz\")\n",
    "    print(f\"Synthesis time: {synthesis_time:.2f}s\")\n",
    "    print(f\"Audio duration: {model_results[model_name]['duration']:.2f}s\")\n",
    "    print(f\"Real-time factor: {model_results[model_name]['rtf']:.2f}x\")\n",
    "    \n",
    "    display(Audio(audio, rate=model.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated audio to files\n",
    "output_dir = Path(\"demo_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the pipeline result\n",
    "output_file = output_dir / \"pipeline_demo.wav\"\n",
    "sf.write(output_file, audio, sample_rate)\n",
    "print(f\"Saved pipeline demo to: {output_file}\")\n",
    "\n",
    "# Save model comparison results\n",
    "for model_name, result in model_results.items():\n",
    "    output_file = output_dir / f\"{model_name.lower()}_comparison.wav\"\n",
    "    sf.write(output_file, result[\"audio\"], result[\"sample_rate\"])\n",
    "    print(f\"Saved {model_name} comparison to: {output_file}\")\n",
    "\n",
    "print(f\"\\nAll demo outputs saved to: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key features of Catalyst AI Voice Studio:\n",
    "\n",
    "1. **Basic TTS Synthesis** - Simple text-to-speech conversion\n",
    "2. **Text Normalization** - Converting numbers, abbreviations, and symbols\n",
    "3. **Prosody Planning** - Adding pauses and emphasis markers\n",
    "4. **Complete Pipeline** - End-to-end processing workflow\n",
    "5. **Voice Comparison** - Testing different voice models\n",
    "6. **Audio Visualization** - Waveform and spectrogram analysis\n",
    "7. **Streaming Synthesis** - Real-time audio generation\n",
    "8. **Model Comparison** - Performance comparison between models\n",
    "9. **File Output** - Saving generated audio\n",
    "\n",
    "The platform provides a flexible and extensible architecture for professional voice synthesis applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}